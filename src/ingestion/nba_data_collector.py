#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Collecteur de donn√©es NBA pour DataLake
R√©cup√®re et structure les donn√©es depuis l'API NBA officielle
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from nba_api.stats.endpoints import (
    playercareerstats, teamyearbyyearstats, leagueleaders,
    playergamelog, teamgamelog, commonplayerinfo
)
from nba_api.stats.static import players, teams
from nba_api.live.nba.endpoints import scoreboard
import pandas as pd
import json
from datetime import datetime, timedelta
import time
import logging
from typing import Dict, List, Optional, Tuple

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data/ingestion.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class NBADataCollector:
    """Collecteur principal de donn√©es NBA pour DataLake"""
    
    def __init__(self, output_dir: str = 'data'):
        # Import de la configuration
        import sys
        import os
        # Ajouter le r√©pertoire racine au path pour trouver config.py
        root_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        if root_dir not in sys.path:
            sys.path.insert(0, root_dir)
        
        from config import NBA_API_CONFIG
        self.config = NBA_API_CONFIG
        self.output_dir = output_dir
        self.metadata = {
            'session_id': datetime.now().strftime('%Y%m%d_%H%M%S'),
            'start_time': datetime.now().isoformat(),
            'api_version': 'nba_api 1.10.0',
            'collected_data': {},
            'errors': []
        }
        
        # Cr√©ation du dossier de sortie avec s√©paration par source
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(f'{output_dir}/raw/api_nba', exist_ok=True)  # Donn√©es NBA API
        os.makedirs(f'{output_dir}/raw/kaggle', exist_ok=True)   # Donn√©es Kaggle
        os.makedirs(f'{output_dir}/processed', exist_ok=True)
        os.makedirs(f'{output_dir}/metadata', exist_ok=True)
        
        logger.info(f"Collecteur NBA initialis√© - Session: {self.metadata['session_id']}")
    
    def collect_players_static(self) -> pd.DataFrame:
        """Collecte des informations statiques sur tous les joueurs"""
        logger.info("Collecte des informations statiques des joueurs...")
        
        try:
            all_players = players.get_players()
            players_df = pd.DataFrame(all_players)
            
            # Sauvegarde des donn√©es brutes
            raw_path = f'{self.output_dir}/raw/api_nba/players_static_{self.metadata["session_id"]}.csv'
            players_df.to_csv(raw_path, index=False)
            
            # Ajout aux m√©tadonn√©es
            self.metadata['collected_data']['players_static'] = {
                'count': len(players_df),
                'raw_file': raw_path,
                'columns': list(players_df.columns)
            }
            
            logger.info(f"‚úÖ {len(players_df)} joueurs collect√©s et sauvegard√©s")
            return players_df
            
        except Exception as e:
            error_msg = f"Erreur collecte joueurs statiques: {e}"
            logger.error(error_msg)
            self.metadata['errors'].append(error_msg)
            return pd.DataFrame()
    
    def collect_teams_static(self) -> pd.DataFrame:
        """Collecte des informations statiques sur toutes les √©quipes"""
        logger.info("Collecte des informations statiques des √©quipes...")
        
        try:
            all_teams = teams.get_teams()
            teams_df = pd.DataFrame(all_teams)
            
            # Sauvegarde des donn√©es brutes
            raw_path = f'{self.output_dir}/raw/api_nba/teams_static_{self.metadata["session_id"]}.csv'
            teams_df.to_csv(raw_path, index=False)
            
            # Ajout aux m√©tadonn√©es
            self.metadata['collected_data']['teams_static'] = {
                'count': len(teams_df),
                'raw_file': raw_path,
                'columns': list(teams_df.columns)
            }
            
            logger.info(f"‚úÖ {len(teams_df)} √©quipes collect√©es et sauvegard√©es")
            return teams_df
            
        except Exception as e:
            error_msg = f"Erreur collecte √©quipes statiques: {e}"
            logger.error(error_msg)
            self.metadata['errors'].append(error_msg)
            return pd.DataFrame()
    
    def collect_player_career_stats(self, player_ids: List[str] = None, limit: int = None) -> Dict[str, pd.DataFrame]:
        """Collecte des statistiques de carri√®re pour les joueurs actifs (limite configurable)"""
        
        # Utiliser la configuration pour la limite
        max_players = limit if limit is not None else self.config['max_players']
        
        logger.info(f"Collecte des statistiques de carri√®re pour les {max_players} premiers joueurs actifs...")
        
        if player_ids is None:
            # Collecte des joueurs actifs selon la limite configur√©e
            all_players = players.get_active_players()
            player_ids = [player['id'] for player in all_players[:max_players]]
            logger.info(f"Collecte des stats de carri√®re pour {len(player_ids)} joueurs actifs (limite: {max_players})")
        elif limit:
            player_ids = player_ids[:limit]
        
        career_stats = {}
        total_processed = 0
        
        for i, player_id in enumerate(player_ids):
            try:
                if i % 10 == 0:  # Log tous les 10 joueurs
                    logger.info(f"Collecte joueur {i+1}/{len(player_ids)} - ID: {player_id}")
                
                # R√©cup√©ration des stats de carri√®re
                stats = playercareerstats.PlayerCareerStats(player_id=player_id)
                stats_df = stats.get_data_frames()[0]
                
                if not stats_df.empty:
                    # R√©cup√©ration des infos du joueur
                    player_info = commonplayerinfo.CommonPlayerInfo(player_id=player_id)
                    info_df = player_info.get_data_frames()[0]
                    
                    if not info_df.empty:
                        player_name = info_df.iloc[0]['DISPLAY_FIRST_LAST']
                        career_stats[player_name] = stats_df
                        total_processed += 1
                        
                        logger.info(f"‚úÖ {player_name}: {len(stats_df)} saisons collect√©es")
                
                # Pause pour √©viter la surcharge de l'API
                time.sleep(self.config['delay'])
                
            except Exception as e:
                error_msg = f"Erreur collecte stats joueur {player_id}: {e}"
                logger.error(error_msg)
                self.metadata['errors'].append(error_msg)
                continue
        
        # Sauvegarde de TOUTES les stats de carri√®re dans un seul fichier
        if career_stats:
            all_career_stats = pd.concat(career_stats.values(), ignore_index=True)
            raw_path = f'{self.output_dir}/raw/api_nba/career_stats_ALL_{self.metadata["session_id"]}.csv'
            all_career_stats.to_csv(raw_path, index=False)
            logger.info(f"‚úÖ Toutes les stats de carri√®re sauvegard√©es: {raw_path}")
        
        # Ajout aux m√©tadonn√©es
        self.metadata['collected_data']['player_career_stats'] = {
            'players_processed': total_processed,
            'total_seasons': sum(len(df) for df in career_stats.values()),
            'total_file': raw_path if career_stats else None
        }
        
        return career_stats
    
    def collect_team_season_stats(self, team_ids: List[str] = None, seasons: List[str] = None) -> Dict[str, pd.DataFrame]:
        """Collecte des statistiques saisonni√®res pour TOUTES les √©quipes"""
        logger.info("Collecte des statistiques saisonni√®res pour TOUTES les √©quipes...")
        
        if team_ids is None:
            # Collecte de TOUTES les √©quipes actuelles
            all_teams = teams.get_teams()
            team_ids = [team['id'] for team in all_teams]
            logger.info(f"Collecte des stats pour {len(team_ids)} √©quipes")
        
        if seasons is None:
            # Utiliser la configuration pour les saisons
            start_year = self.config['start_year']
            current_year = self.config['current_year']
            seasons = [f"{year}-{str(year+1)[-2:]}" for year in range(start_year, current_year+1)]
        
        team_stats = {}
        total_processed = 0
        
        for team_id in team_ids:
            try:
                logger.info(f"Collecte √©quipe ID: {team_id}")
                
                # R√©cup√©ration des stats par saison
                stats = teamyearbyyearstats.TeamYearByYearStats(team_id=team_id)
                stats_df = stats.get_data_frames()[0]
                
                # Filtrage par saisons demand√©es
                if seasons:
                    stats_df = stats_df[stats_df['YEAR'].isin(seasons)]
                
                if not stats_df.empty:
                    team_stats[team_id] = stats_df
                    
                    # Sauvegarde des donn√©es brutes
                    raw_path = f'{self.output_dir}/raw/api_nba/team_stats_{team_id}_{self.metadata["session_id"]}.csv'
                    stats_df.to_csv(raw_path, index=False)
                    
                    logger.info(f"‚úÖ √âquipe {team_id}: {len(stats_df)} saisons collect√©es")
                
                time.sleep(self.config['delay'])
                
            except Exception as e:
                error_msg = f"Erreur collecte stats √©quipe {team_id}: {e}"
                logger.error(error_msg)
                self.metadata['errors'].append(error_msg)
                continue
        
        # Sauvegarde de TOUTES les stats d'√©quipes dans un seul fichier
        if team_stats:
            all_team_stats = pd.concat(team_stats.values(), ignore_index=True)
            raw_path = f'{self.output_dir}/raw/api_nba/team_stats_ALL_{self.metadata["session_id"]}.csv'
            all_team_stats.to_csv(raw_path, index=False)
            logger.info(f"‚úÖ Toutes les stats d'√©quipes sauvegard√©es: {raw_path}")
        
        # Ajout aux m√©tadonn√©es
        self.metadata['collected_data']['team_season_stats'] = {
            'teams_processed': len(team_stats),
            'total_seasons': sum(len(df) for df in team_stats.values()),
            'total_file': raw_path if team_stats else None
        }
        
        return team_stats
    
    def collect_current_leaders(self) -> Dict[str, pd.DataFrame]:
        """Collecte des leaders actuels de la NBA pour TOUTES les cat√©gories"""
        logger.info("Collecte des leaders actuels pour TOUTES les cat√©gories...")
        
        leaders_data = {}
        # TOUTES les cat√©gories de leaders disponibles
        stat_categories = ['PTS', 'REB', 'AST', 'STL', 'BLK', 'FG_PCT', 'FG3_PCT', 'FT_PCT', 'MIN', 'GP', 'EFF', 'AST_TOV', 'STL_TOV']
        
        for category in stat_categories:
            try:
                logger.info(f"Collecte leaders: {category}")
                
                current_year = datetime.now().year
                current_season = f"{current_year-1}-{str(current_year)[-2:]}"
                
                leaders = leagueleaders.LeagueLeaders(
                    stat_category_abbreviation=category,
                    season=current_season,
                    season_type_all_star='Regular Season'
                )
                
                leaders_df = leaders.get_data_frames()[0]
                leaders_data[category] = leaders_df
                
                # Sauvegarde des donn√©es brutes
                raw_path = f'{self.output_dir}/raw/api_nba/leaders_{category}_{self.metadata["session_id"]}.csv'
                leaders_df.to_csv(raw_path, index=False)
                
                logger.info(f"‚úÖ Leaders {category}: {len(leaders_df)} joueurs collect√©s")
                
                time.sleep(self.config['delay'])  # Pause configurable
                
            except Exception as e:
                error_msg = f"Erreur collecte leaders {category}: {e}"
                logger.error(error_msg)
                self.metadata['errors'].append(error_msg)
                continue
        
        # Sauvegarde de TOUS les leaders dans un seul fichier
        if leaders_data:
            all_leaders = pd.concat(leaders_data.values(), ignore_index=True)
            raw_path = f'{self.output_dir}/raw/api_nba/leaders_ALL_{self.metadata["session_id"]}.csv'
            all_leaders.to_csv(raw_path, index=False)
            logger.info(f"‚úÖ Tous les leaders sauvegard√©s: {raw_path}")
        
        # Ajout aux m√©tadonn√©es
        self.metadata['collected_data']['current_leaders'] = {
            'categories_processed': len(leaders_data),
            'total_players': sum(len(df) for df in leaders_data.values()),
            'total_file': raw_path if leaders_data else None
        }
        
        return leaders_data
    
    def save_metadata(self):
        """Sauvegarde des m√©tadonn√©es de la session"""
        self.metadata['end_time'] = datetime.now().isoformat()
        self.metadata['duration'] = (
            datetime.fromisoformat(self.metadata['end_time']) - 
            datetime.fromisoformat(self.metadata['start_time'])
        ).total_seconds()
        
        metadata_path = f'{self.output_dir}/metadata/session_{self.metadata["session_id"]}.json'
        
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ M√©tadonn√©es sauvegard√©es: {metadata_path}")
        
        return metadata_path
    
    def run_full_collection(self) -> Dict:
        """Ex√©cute la collecte compl√®te des donn√©es NBA (limite configurable)"""
        max_players = self.config['max_players']
        logger.info(f"üöÄ D√©marrage de la collecte compl√®te des donn√©es NBA (limite: {max_players} joueurs actifs)")
        
        try:
            # Collecte des donn√©es statiques
            players_static = self.collect_players_static()
            teams_static = self.collect_teams_static()
            
            # Collecte des statistiques d√©taill√©es
            player_career = self.collect_player_career_stats()
            team_season = self.collect_team_season_stats()
            current_leaders = self.collect_current_leaders()
            
            # Sauvegarde des m√©tadonn√©es
            metadata_path = self.save_metadata()
            
            # Mise √† jour des index et m√©tadonn√©es globales
            try:
                from ingestion.metadata_manager import MetadataManager
                metadata_manager = MetadataManager()
                metadata_manager.update_all_metadata()
                logger.info("‚úÖ Index et m√©tadonn√©es globales mis √† jour")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur mise √† jour m√©tadonn√©es globales: {e}")
            
            # R√©sum√© de la collecte
            summary = {
                'session_id': self.metadata['session_id'],
                'players_static': len(players_static),
                'teams_static': len(teams_static),
                'player_careers': len(player_career),
                'team_seasons': len(team_season),
                'leader_categories': len(current_leaders),
                'errors_count': len(self.metadata['errors']),
                'metadata_file': metadata_path
            }
            
            logger.info("‚úÖ Collecte compl√®te termin√©e avec succ√®s")
            logger.info(f"üìä R√©sum√©: {summary}")
            
            return summary
            
        except Exception as e:
            error_msg = f"Erreur critique lors de la collecte: {e}"
            logger.error(error_msg)
            self.metadata['errors'].append(error_msg)
            self.save_metadata()
            raise


